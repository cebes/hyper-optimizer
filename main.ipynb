{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi trip duration\n",
    "\n",
    "Demo of Bayesian optimization. The features and model are inspired by https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367, but was simplified to illustrate BayesOpt instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/nyc-taxi-trip-duration/train.csv')\n",
    "test = pd.read_csv('input/nyc-taxi-trip-duration/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip_duration and datetimes are ok.\n"
     ]
    }
   ],
   "source": [
    "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\n",
    "test['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\n",
    "train.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\n",
    "test.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\n",
    "train['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\n",
    "train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\n",
    "test['store_and_fwd_flag'] = 1 * (test.store_and_fwd_flag.values == 'Y')\n",
    "train['check_trip_duration'] = (train['dropoff_datetime'] - train['pickup_datetime']).map(lambda x: x.total_seconds())\n",
    "duration_difference = train[np.abs(train['check_trip_duration'].values  - train['trip_duration'].values) > 1]\n",
    "print('Trip_duration and datetimes are ok.') if len(duration_difference[['pickup_datetime', 'dropoff_datetime', 'trip_duration', 'check_trip_duration']]) == 0 else print('Ooops.')\n",
    "\n",
    "# Convert trip duration into the log domain, and use RMSE to train the model\n",
    "train['log_trip_duration'] = np.log(train['trip_duration'].values + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n",
    "                    train[['dropoff_latitude', 'dropoff_longitude']].values,\n",
    "                    test[['pickup_latitude', 'pickup_longitude']].values,\n",
    "                    test[['dropoff_latitude', 'dropoff_longitude']].values))\n",
    "\n",
    "pca = PCA().fit(coords)\n",
    "train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "train['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "train['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "train['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "test['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "test['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "test['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "test['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Distances\n",
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "def dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    a = haversine_array(lat1, lng1, lat1, lng2)\n",
    "    b = haversine_array(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "\n",
    "train.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + np.abs(train['dropoff_pca0'] - train['pickup_pca0'])\n",
    "\n",
    "test.loc[:, 'distance_haversine'] = haversine_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    "test.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    "test.loc[:, 'direction'] = bearing_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    "test.loc[:, 'pca_manhattan'] = np.abs(test['dropoff_pca1'] - test['pickup_pca1']) + np.abs(test['dropoff_pca0'] - test['pickup_pca0'])\n",
    "\n",
    "train.loc[:, 'center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2\n",
    "train.loc[:, 'center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\n",
    "test.loc[:, 'center_latitude'] = (test['pickup_latitude'].values + test['dropoff_latitude'].values) / 2\n",
    "test.loc[:, 'center_longitude'] = (test['pickup_longitude'].values + test['dropoff_longitude'].values) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Datetime\n",
    "train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train.loc[:, 'pickup_hour_weekofyear'] = train['pickup_datetime'].dt.weekofyear\n",
    "train.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\n",
    "train.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\n",
    "train.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n",
    "train.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n",
    "\n",
    "test.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\n",
    "test.loc[:, 'pickup_hour_weekofyear'] = test['pickup_datetime'].dt.weekofyear\n",
    "test.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\n",
    "test.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\n",
    "test.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n",
    "test.loc[:, 'pickup_week_hour'] = test['pickup_weekday'] * 24 + test['pickup_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Speed\n",
    "train.loc[:, 'avg_speed_h'] = 1000 * train['distance_haversine'] / train['trip_duration']\n",
    "train.loc[:, 'avg_speed_m'] = 1000 * train['distance_dummy_manhattan'] / train['trip_duration']\n",
    "\n",
    "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 3)\n",
    "train.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 3)\n",
    "# Average speed for regions\n",
    "gby_cols = ['pickup_lat_bin', 'pickup_long_bin']\n",
    "coord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\n",
    "coord_count = train.groupby(gby_cols).count()[['id']].reset_index()\n",
    "coord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\n",
    "coord_stats = coord_stats[coord_stats['id'] > 100]\n",
    "\n",
    "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train.loc[:, 'center_lat_bin'] = np.round(train['center_latitude'], 2)\n",
    "train.loc[:, 'center_long_bin'] = np.round(train['center_longitude'], 2)\n",
    "train.loc[:, 'pickup_dt_bin'] = (train['pickup_dt'] // (3 * 3600))\n",
    "test.loc[:, 'pickup_lat_bin'] = np.round(test['pickup_latitude'], 2)\n",
    "test.loc[:, 'pickup_long_bin'] = np.round(test['pickup_longitude'], 2)\n",
    "test.loc[:, 'center_lat_bin'] = np.round(test['center_latitude'], 2)\n",
    "test.loc[:, 'center_long_bin'] = np.round(test['center_longitude'], 2)\n",
    "test.loc[:, 'pickup_dt_bin'] = (test['pickup_dt'] // (3 * 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "sample_ind = np.random.permutation(len(coords))[:500000]\n",
    "kmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind])\n",
    "\n",
    "train.loc[:, 'pickup_cluster'] = kmeans.predict(train[['pickup_latitude', 'pickup_longitude']])\n",
    "train.loc[:, 'dropoff_cluster'] = kmeans.predict(train[['dropoff_latitude', 'dropoff_longitude']])\n",
    "test.loc[:, 'pickup_cluster'] = kmeans.predict(test[['pickup_latitude', 'pickup_longitude']])\n",
    "test.loc[:, 'dropoff_cluster'] = kmeans.predict(test[['dropoff_latitude', 'dropoff_longitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temporal and geospatial\n",
    "for gby_col in ['pickup_hour', 'pickup_date', 'pickup_dt_bin',\n",
    "               'pickup_week_hour', 'pickup_cluster', 'dropoff_cluster']:\n",
    "    gby = train.groupby(gby_col).mean()[['avg_speed_h', 'avg_speed_m', 'log_trip_duration']]\n",
    "    gby.columns = ['%s_gby_%s' % (col, gby_col) for col in gby.columns]\n",
    "    train = pd.merge(train, gby, how='left', left_on=gby_col, right_index=True)\n",
    "    test = pd.merge(test, gby, how='left', left_on=gby_col, right_index=True)\n",
    "\n",
    "for gby_cols in [['center_lat_bin', 'center_long_bin'],\n",
    "                 ['pickup_hour', 'center_lat_bin', 'center_long_bin'],\n",
    "                 ['pickup_hour', 'pickup_cluster'],  ['pickup_hour', 'dropoff_cluster'],\n",
    "                 ['pickup_cluster', 'dropoff_cluster']]:\n",
    "    coord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\n",
    "    coord_count = train.groupby(gby_cols).count()[['id']].reset_index()\n",
    "    coord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\n",
    "    coord_stats = coord_stats[coord_stats['id'] > 100]\n",
    "    coord_stats.columns = gby_cols + ['avg_speed_h_%s' % '_'.join(gby_cols), 'cnt_%s' %  '_'.join(gby_cols)]\n",
    "    train = pd.merge(train, coord_stats, how='left', on=gby_cols)\n",
    "    test = pd.merge(test, coord_stats, how='left', on=gby_cols)\n",
    "    \n",
    "group_freq = '60min'\n",
    "df_all = pd.concat((train, test))[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\n",
    "train.loc[:, 'pickup_datetime_group'] = train['pickup_datetime'].dt.round(group_freq)\n",
    "test.loc[:, 'pickup_datetime_group'] = test['pickup_datetime'].dt.round(group_freq)\n",
    "\n",
    "# Count trips over 60min\n",
    "df_counts = df_all.set_index('pickup_datetime')[['id']].sort_index()\n",
    "df_counts['count_60min'] = df_counts.isnull().rolling(group_freq).count()['id']\n",
    "train = train.merge(df_counts, on='id', how='left')\n",
    "test = test.merge(df_counts, on='id', how='left')\n",
    "\n",
    "# Count how many trips are going to each cluster over time\n",
    "dropoff_counts = df_all \\\n",
    "    .set_index('pickup_datetime') \\\n",
    "    .groupby([pd.TimeGrouper(group_freq), 'dropoff_cluster']) \\\n",
    "    .agg({'id': 'count'}) \\\n",
    "    .reset_index().set_index('pickup_datetime') \\\n",
    "    .groupby('dropoff_cluster').rolling('240min').mean() \\\n",
    "    .drop('dropoff_cluster', axis=1) \\\n",
    "    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n",
    "    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'dropoff_cluster_count'})\n",
    "\n",
    "train['dropoff_cluster_count'] = train[['pickup_datetime_group', 'dropoff_cluster']].merge(dropoff_counts, on=['pickup_datetime_group', 'dropoff_cluster'], how='left')['dropoff_cluster_count'].fillna(0)\n",
    "test['dropoff_cluster_count'] = test[['pickup_datetime_group', 'dropoff_cluster']].merge(dropoff_counts, on=['pickup_datetime_group', 'dropoff_cluster'], how='left')['dropoff_cluster_count'].fillna(0)\n",
    "\n",
    "# Count how many trips are going from each cluster over time\n",
    "df_all = pd.concat((train, test))[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\n",
    "pickup_counts = df_all \\\n",
    "    .set_index('pickup_datetime') \\\n",
    "    .groupby([pd.TimeGrouper(group_freq), 'pickup_cluster']) \\\n",
    "    .agg({'id': 'count'}) \\\n",
    "    .reset_index().set_index('pickup_datetime') \\\n",
    "    .groupby('pickup_cluster').rolling('240min').mean() \\\n",
    "    .drop('pickup_cluster', axis=1) \\\n",
    "    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n",
    "    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'pickup_cluster_count'})\n",
    "\n",
    "train['pickup_cluster_count'] = train[['pickup_datetime_group', 'pickup_cluster']].merge(pickup_counts, on=['pickup_datetime_group', 'pickup_cluster'], how='left')['pickup_cluster_count'].fillna(0)\n",
    "test['pickup_cluster_count'] = test[['pickup_datetime_group', 'pickup_cluster']].merge(pickup_counts, on=['pickup_datetime_group', 'pickup_cluster'], how='left')['pickup_cluster_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_speed_h' 'avg_speed_m' 'check_trip_duration' 'dropoff_datetime'\n",
      " 'log_trip_duration' 'trip_duration']\n",
      "We have 59 features.\n"
     ]
    }
   ],
   "source": [
    "# OSRM features\n",
    "fr1 = pd.read_csv('input/new-york-city-taxi-with-osrm/fastest_routes_train_part_1.csv', usecols=['id', 'total_distance', 'total_travel_time',  'number_of_steps'])\n",
    "fr2 = pd.read_csv('input/new-york-city-taxi-with-osrm/fastest_routes_train_part_2.csv', usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps'])\n",
    "test_street_info = pd.read_csv('input/new-york-city-taxi-with-osrm/fastest_routes_test.csv',\n",
    "                               usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps'])\n",
    "train_street_info = pd.concat((fr1, fr2))\n",
    "train = train.merge(train_street_info, how='left', on='id')\n",
    "test = test.merge(test_street_info, how='left', on='id')\n",
    "\n",
    "feature_names = list(train.columns)\n",
    "print(np.setdiff1d(train.columns, test.columns))\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime', 'trip_duration', 'check_trip_duration',\n",
    "                           'pickup_date', 'avg_speed_h', 'avg_speed_m', 'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin', 'pickup_dt_bin', 'pickup_datetime_group']\n",
    "feature_names = [f for f in train.columns if f not in do_not_use_for_training]\n",
    "# print(feature_names)\n",
    "print('We have %i features.' % len(feature_names))\n",
    "train[feature_names].count()\n",
    "y = np.log(train['trip_duration'].values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>train_test_mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>avg_speed_h_pickup_cluster_dropoff_cluster</td>\n",
       "      <td>0.002666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pickup_pca0</td>\n",
       "      <td>0.002774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dropoff_pca1</td>\n",
       "      <td>0.002833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pickup_hour_weekofyear</td>\n",
       "      <td>0.002872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dropoff_cluster</td>\n",
       "      <td>0.002911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       feature  train_test_mean_diff\n",
       "51  avg_speed_h_pickup_cluster_dropoff_cluster              0.002666\n",
       "7                                  pickup_pca0              0.002774\n",
       "10                                dropoff_pca1              0.002833\n",
       "18                      pickup_hour_weekofyear              0.002872\n",
       "24                             dropoff_cluster              0.002911"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "feature_stats = pd.DataFrame({'feature': feature_names})\n",
    "feature_stats.loc[:, 'train_mean'] = np.nanmean(train[feature_names].values, axis=0).round(4)\n",
    "feature_stats.loc[:, 'test_mean'] = np.nanmean(test[feature_names].values, axis=0).round(4)\n",
    "feature_stats.loc[:, 'train_std'] = np.nanstd(train[feature_names].values, axis=0).round(4)\n",
    "feature_stats.loc[:, 'test_std'] = np.nanstd(test[feature_names].values, axis=0).round(4)\n",
    "feature_stats.loc[:, 'train_nan'] = np.mean(np.isnan(train[feature_names].values), axis=0).round(3)\n",
    "feature_stats.loc[:, 'test_nan'] = np.mean(np.isnan(test[feature_names].values), axis=0).round(3)\n",
    "feature_stats.loc[:, 'train_test_mean_diff'] = np.abs(feature_stats['train_mean'] - feature_stats['test_mean']) / np.abs(feature_stats['train_std'] + feature_stats['test_std'])  * 2\n",
    "feature_stats.loc[:, 'train_test_nan_diff'] = np.abs(feature_stats['train_nan'] - feature_stats['test_nan'])\n",
    "feature_stats = feature_stats.sort_values(by='train_test_mean_diff')\n",
    "feature_stats[['feature', 'train_test_mean_diff']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>train_nan</th>\n",
       "      <th>test_nan</th>\n",
       "      <th>train_test_nan_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dropoff_cluster</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>avg_speed_h_pickup_hour_dropoff_cluster</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>cnt_pickup_hour_dropoff_cluster</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>cnt_pickup_cluster_dropoff_cluster</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>avg_speed_h_pickup_cluster_dropoff_cluster</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       feature  train_nan  test_nan  \\\n",
       "24                             dropoff_cluster      0.000     0.000   \n",
       "49     avg_speed_h_pickup_hour_dropoff_cluster      0.018     0.019   \n",
       "50             cnt_pickup_hour_dropoff_cluster      0.018     0.019   \n",
       "52          cnt_pickup_cluster_dropoff_cluster      0.097     0.099   \n",
       "51  avg_speed_h_pickup_cluster_dropoff_cluster      0.097     0.099   \n",
       "\n",
       "    train_test_nan_diff  \n",
       "24                0.000  \n",
       "49                0.001  \n",
       "50                0.001  \n",
       "52                0.002  \n",
       "51                0.002  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_stats = feature_stats.sort_values(by='train_test_nan_diff')\n",
    "feature_stats[['feature', 'train_nan', 'test_nan', 'train_test_nan_diff']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "dtest = xgb.DMatrix(test[feature_names].values)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "# Try different parameters! My favorite is random search :)\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 10,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "\n",
    "model = xgb.train(xgb_pars, dtrain, 60, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=10)\n",
    "\n",
    "print('Modeling RMSLE %.5f' % model.best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
